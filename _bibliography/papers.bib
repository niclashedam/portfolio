
@inproceedings{damme_daphne_2022,
	address = {Santa Cruz, California, USA},
	title = {{DAPHNE}: {An} {Open} and {Extensible} {System} {Infrastructurefor} {Integrated} {Data} {Analysis} {Pipelines}},
	copyright = {All rights reserved},
	url = {https://www.cidrdb.org/cidr2022/papers/p4-damme.pdf},
	abstract = {Integrated data analysis (IDA) pipelines—that combine data management (DM) and query processing, high-performance computing (HPC), and machine learning (ML) training and scoring—become increasingly common in practice. Interestingly, systems of these areas share many compilation and runtime techniques, and the used—increasingly heterogeneous—hardware infrastructure converges as well. Yet, the programming paradigms, cluster resource management, data formats and representations, as well as execution strategies differ substantially. DAPHNE is an open and extensible system infrastructure for such IDA pipelines, including language abstractions, compilation and runtime techniques, multi-level scheduling, hardware (HW) accelerators, and computational storage for increasing productivity and eliminating unnecessary overheads. In this paper, we make a case for IDA pipelines, describe the overall DAPHNE system architecture, its key components, and the design of a vectorized execution engine for computational storage, HW accelerators, as well as local and distributed operations. Preliminary experiments that compare DAPHNE with MonetDB, Pandas, DuckDB, and TensorFlow show promising results.},
	language = {en},
	booktitle = {12th {Annual} {Conference} on {Innovative} {Data} {Systems} {Research} ({CIDR} ‘22)},
	publisher = {CIDR},
	author = {Damme, Patrick and Birkenbach, Marius and Bitsakos, Constantinos and Boehm, Matthias and Bonnet, Philippe and Ciorba, Florina and Dokter, Mark and Dowgiallo, Pawel and Eleliemy, Ahmed and Faerber, Christian and Goumas, Georgios and Habich, Dirk and Hedam, Niclas and Hofer, Marlies and Huang, Wenjun and Innerebner, Kevin and Karakostas, Vasileios and Kern, Roman and Kosar, Tomaž and Krause, Alexander and Krems, Daniel and Laber, Andreas and Lehner, Wolfgang and Mier, Eric and Paradies, Marcus and Peischl, Bernhard and Poerwawinata, Gabrielle and Psomadakis, Stratos and Rabl, Tilmann and Ratuszniak, Piotr and Silva, Pedro and Skuppin, Nikolai and Starzacher, Andreas and Steinwender, Benjamin and Tolovski, Ilin and Tözün, Pınar and Ulatowski, Wojciech and Wang, Yuanyuan and Wrosz, Izajasz and Zamuda, Aleš and Zhang, Ce and Zhu, Xiao Xiang},
	month = jan,
	year = {2022},
	file = {Damme et al. - 2022 - DAPHNE An Open and Extensible System Infrastructu.pdf:/Users/nhed/Zotero/storage/XQU8XBAS/Damme et al. - 2022 - DAPHNE An Open and Extensible System Infrastructu.pdf:application/pdf},
}

@inproceedings{picoli_open-channel_2020,
	address = {Amsterdam, Netherlands},
	title = {Open-{Channel} {SSD} ({What} is it {Good} {For})},
	copyright = {All rights reserved},
	url = {https://www.cidrdb.org/cidr2020/papers/p17-picoli-cidr20.pdf},
	abstract = {Open-Channel SSDs are storage devices that let hosts take full control over data placement and I/O scheduling. In recent years, they have gained acceptance in data centers (e.g., Alibaba) and for computational storage (e.g., Pliops). Open-Channel SSDs require a host-based Flash Translation Layer (FTL) that manages the physical address space they expose. Open-source FTLs are now available for OpenChannel SSDs, providing either a generic yet tunable block device interface (e.g., pblk, SPDK, OX-Block), or applicationspeciﬁc FTLs developed for a speciﬁc data system (e.g., LightLSM, OX-ELEOS). In this paper, we share our experience developing three of those FTLs in the context of the OX controller. We position Open-Channel SSDs in the SSD landscape and discuss their relevance for data systems. In particular, we argue that Open-Channel SSDs cannot be considered as a uniform class of devices. Our main contribution is a description of the key design decisions we took in OX related to Open-Channel SSDs. We reﬂect on lessons learned and propose hints for the co-design of data systems and Open-Channel SSDs.},
	language = {en},
	booktitle = {10th {Annual} {Conference} on {Innovative} {Data} {Systems} {Research} ({CIDR} ‘20)},
	publisher = {CIDR},
	author = {Picoli, Ivan Luiz and Hedam, Niclas and Tözün, Pınar and Bonnet, Philippe},
	month = jan,
	year = {2020},
	file = {Picoli et al. - 2020 - Open-Channel SSD (What is it Good For).pdf:/Users/nhed/Zotero/storage/4E8FRFZK/Picoli et al. - 2020 - Open-Channel SSD (What is it Good For).pdf:application/pdf},
}

@inproceedings{hedam_hash-based_2020,
	address = {Tokyo, Japan},
	title = {Hash-{Based} {Authentication} {Revisited} in the {Age} of {High}-{Performance} {Computers}},
	copyright = {All rights reserved},
	url = {https://adms-conf.org/2020-camera-ready/ADMS20_02.pdf},
	abstract = {Hash-based authentication is a widespread technique for protecting passwords in many modern software systems including databases. A hashing function is a one-way mathematical function that is used in various security contexts in this domain. In this paper, we revisit three popular hashing algorithms (MD5, SHA-1, and NTLM), that are considered weak or insecure. More specifically, we explore the performance of the hashing algorithms on different hardware platforms, from expensive high-end GPUs found in data centers and high-performance computing centers to relatively cheaper consumer-grade ones found in the homes of end-users. In parallel, we observe the behavior of different hardware platforms. Our results re-emphasize that despite their theoretical strength, the practical utilization of widely used hashing algorithms are highly insecure in many real-world scenarios; i.e., cracking a password of length 6 takes less than 6 seconds using a consumer-grade GPU.},
	language = {en},
	booktitle = {11th {International} {Workshop} on {Accelerating} {Analytics} and {Data} {Management} {Systems} ({ADMS} '20)},
	publisher = {ADMS},
	author = {Hedam, Niclas and Mollerup, Jakob and Tözün, Pınar},
	month = aug,
	year = {2020},
	file = {Hedam et al. - 2020 - Hash-Based Authentication Revisited in the Age of .pdf:/Users/nhed/Zotero/storage/47G22798/Hedam et al. - 2020 - Hash-Based Authentication Revisited in the Age of .pdf:application/pdf},
}

@misc{hedam_ebpf_2021,
	title = {{eBPF} - {From} a {Programmer}'s {Perspective}},
	copyright = {Attribution-NoDerivatives 4.0 International (CC BY-ND 4.0)},
	url = {http://rgdoi.net/10.13140/RG.2.2.33688.11529/3},
	doi = {10.13140/RG.2.2.33688.11529/3},
	abstract = {eBPF allows software developers to write programs that are executed in the kernel without requiring recompilation and system restart. These programs can collect critical performance metrics when a kernel function is invoked. In this paper, we will describe and discuss the architecture of eBPF using libbpf as well as the core components of it. We will look at key differences between eBPF programs and typical user-space C programs. Lastly, we will look into some real-world use-cases of eBPF. We will, however, not discuss performance numbers or formal proofs. This paper is merely a summary of countless hours of reading through eBPF textbooks, blog posts, eBPF samples and kernel code.},
	language = {en},
	urldate = {2021-12-06},
	author = {Hedam, Niclas},
	month = mar,
	year = {2021},
	note = {Version Number: 3},
	file = {Hedam - 2021 - eBPF - From a Programmer's Perspective.pdf:/Users/nhed/Zotero/storage/TQAIP7HY/Hedam - 2021 - eBPF - From a Programmer's Perspective.pdf:application/pdf},
}

@inproceedings{hedam_delilah_2023,
	address = {Seattle, Washington, USA},
	title = {Delilah: {eBPF}-offload on {Computational} {Storage}},
	copyright = {Creative Commons Attribution 4.0 International Licence (CC-BY)},
	url = {https://hed.am/papers/2023-DaMoN.pdf},
	doi = {10.1145/3592980.3595319},
	abstract = {The idea of pushing computation to storage devices has been explored for decades, without widespread adoption so far. The definition of Computational Programs namespaces in NVMe (TP 4091) might be a breakthrough. The proposal defines device-specific programs, that are installed statically, and downloadable programs, offloaded from a host at run-time using eBPF. In this paper, we present the design and implementation of Delilah, the first public description of an actual computational storage device supporting eBPF-based code offload. We conduct experiments to evaluate the overhead of eBPF function execution in Delilah, and to explore design options. This study constitutes a baseline for future work.},
	language = {en},
	booktitle = {19th {International} {Workshop} on {Data} {Management} on {New} {Hardware} ({DaMoN} ’23)},
	publisher = {DaMoN},
	author = {Hedam, Niclas and Clausen, Morten Tychsen and Bonnet, Philippe and Lee, Sangjin and Larsen, Ken Friis},
	year = {2023},
	file = {Hedam et al. - 2023 - Delilah eBPF-offload on Computational Storage.pdf:/Users/nhed/Zotero/storage/V6GKQTY3/Hedam et al. - 2023 - Delilah eBPF-offload on Computational Storage.pdf:application/pdf},
}
